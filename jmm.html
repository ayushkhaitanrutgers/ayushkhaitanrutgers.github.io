<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Panel on the Use of AI Tools for Mathematics Research</title>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&family=Roboto+Slab:wght@700&display=swap" rel="stylesheet">
<style>
  body {
    font-family: 'Open Sans', sans-serif;
    line-height: 1.6;
    color: #333;
    background-color: #f8f8f8;
    padding: 20px;
  }
  h1, h2 {
    font-family: 'Roboto Slab', serif;
    color: #2c3e50;
    margin-bottom: 20px;
  }
  p {
    font-size: 18px;
    color: #555;
    max-width: 800px;
  }
  .container {
    max-width: 800px;
    margin: auto;
    padding: 20px;
    background-color: #fff;
    box-shadow: 0 0 10px rgba(0, 0, 0, 0.05);
  }
  a {
    color: #2980b9;
    text-decoration: none;
  }
  a:hover {
    text-decoration: underline;
  }
  ul {
    padding-left: 20px;
  }
  .panelists {
    list-style-type: none;
    padding: 0;
  }
  .panelists li {
    margin-bottom: 10px;
  }
  .question {
    font-weight: 600;
    margin-top: 20px;
  }
  .response {
    margin-left: 20px;
    margin-top: 10px;
  }
  .moderator {
    font-style: italic;
    margin-left: 20px;
    margin-top: 10px;
  }
</style>
</head>
<body>

<div class="container">
  <h1>Panel on the Use of AI Tools for Mathematics Research</h1>

  <div class="response">
    <p> Given below is our recollection of the panelists' opinions and ideas at our [JMM panel](https://meetings.ams.org/math/jmm2025/meetingapp.cgi/Session/11074). Any factual errors are the author's alone.</p>
  </div>
  
  <h2>Panelists</h2>
  <ul class="panelists">
    <li>Francois Charton (FAIR, Meta)</li>
    <li>Thomas Hubert (Google DeepMind)</li>
    <li>Alex Kontorovich (Rutgers University)</li>
    <li>Kaiyu Yang (FAIR, Meta)</li>
  </ul>
  
  <div class="question">
    <p>Question 1: What AI tools are currently being used in mathematics?</p>
  </div>
  <div class="response">
    <p><strong>Alex:</strong> Foundational LLMs like ChatGPT, Claude, etc., are the tools most used by mathematicians for their research. Tools like Lean are also being adopted. Other tools include FunSearch, AlphaGeometry, PatternBoost, etc. DeepMind seems to be very secretive about the Alpha family of technologies, but it would be great if math professors had access to them to solve their problems.</p>
  </div>
  <div class="response">
    <p><strong>Francois:</strong> Although I am an engineer, not a mathematician, I participated in a semester-long workshop last year at Harvard CMSA, where I helped with many complicated math problems using basic Transformers. Hence, it is likely that Transformers can understand complex mathematics and provide answers that seem difficult for even professional mathematicians to compute.</p>
  </div>
  
  <div class="question">
    <p>Question 2: Both FunSearch and PatternBoost are based on the genetic evolution of programs, or perhaps mathematical constructions. Currently, these technologies have only been used to construct examples/counterexamples in combinatorics. However, both papers mention that these technologies can be used in other fields as well. What are the obstacles to using these technologies to construct examples in, say, differential geometry or analysis?</p>
  </div>
  <div class="response">
    <p><strong>Francois:</strong> Yes, it seems that combinatorics problems may be more amenable to such methods due to the finite search space.</p>
  </div>
  <div class="moderator">
    <p>Moderator: But even for problems in geometry, there seems to be a finite list of manifolds that mathematicians check before they write down or disprove a conjecture. Could it be possible to automate this with LLMs, perhaps through the use of FunSearch or PatternBoost?</p>
  </div>
  <div class="response">
    <p><strong>Francois:</strong> It seems to me that geometry problems should also be amenable to our methods by dividing up manifolds into a finite number of components. This is something we’d be interested in exploring.</p>
  </div>
  
  <div class="question">
    <p>Question 3: AlphaProof is almost at the level of a gold medalist at the IMO. Can these skills be transferred to proving research-level problems in mathematics? How is this skill transfer different in humans compared to transformers?</p>
  </div>
  <div class="response">
    <p><strong>Thomas:</strong> We can’t comment on our current efforts in creating or using AI tools for math research, but it is our understanding that grounding LLMs with formal theorem provers will continue to yield results.</p>
  </div>
  <div class="response">
    <p><strong>Kaiyu:</strong> Recall that the only problems that AlphaProof wasn’t able to solve on the 2024 IMO were the two combinatorics problems. The way that AlphaProof works is that first the problems are manually translated into Lean, and then AlphaProof tries to write a proof in Lean. One of the combinatorics problems was written in terms of “monsters” being on certain boxes of the checkerboard; clearly, these terms are difficult to translate into Lean. That could have been one of the reasons why AlphaProof was not able to solve the problem. It is possible that the scope of LLMs coupled to formal proof systems extends to the most difficult math problems, including research-level problems.</p>
  </div>
  
  <div class="question">
    <p>Question 4: Kaiyu, in your recent position paper, you argue that grounding an LLM in Lean is indispensable to making it reliably good at theorem proving. However, OpenAI’s O3 is able to prove 19/20 problems at the AIME without using formal theorem provers. How confident are you in your prediction that formal theorem provers will be indispensable in advancing AI4Math?</p>
  </div>
    <div class="response">
    <p><strong>Kaiyu:</strong> I'd first like to clarify that we talk about grounding LLMs with formal theorem provers, of which Lean is only one example. Some fields of mathematics are more suited to other formal theorem provers. Secondly, no one knows for certain how OpenAI's O3 is able to solve 19/20 problems on the AIME, but they probably have a verifier that verifies math proofs. It will be interesting to know if it is easier or faster to couple an LLM with a trained verifier or to couple it with a formal theorem prover. This is the major distinction between OpenAI's approach and ours, as stated in the position paper.</p>
  </div>

  <div class="question">
    <p>Question 5: It seems to me that LLMs don't have a real understanding of mathematical concepts. They can only really "understand" things that can be written in a natural language sentence. Hence, although they may be able to write poetry and stories, they can't reliably solve math problems by just predicting the next token.</p>
  </div>
  <div class="response">
    <p><strong>Francois:</strong> Mathematical formulas can also be written down as a sentence. This was the theme of my research the whole of last semester at Harvard CMSA. We found a way to encode mathematical questions and formulas as sentences, and successfully trained a transformer to, essentially, translate these questions into answers as one would translate an English sentence into French.</p>
  </div>
  <div class="response">
    <p><strong>Alex:</strong> What I meant is that ChatGPT, although it has read all books on chess that exist, cannot reliably play a game of chess by telling you the moves in English. Hence, it can't really be said that it understands how to play Chess.</p>
  </div>
  <div class="response">
    <p><strong>Francois:</strong> In my experience, transformer architectures can reliably solve most mathematical problems/logical puzzles that they have been trained/fine-tuned on.  
  </div>

</div>

</body>
</html>

 
