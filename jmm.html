<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Panel on the Use of AI Tools for Mathematics Research</title>
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&family=Roboto+Slab:wght@700&display=swap" rel="stylesheet">
<style>
  body {
    font-family: 'Open Sans', sans-serif;
    line-height: 1.6;
    color: #333;
    background-color: #f8f8f8;
    padding: 20px;
  }
  h1, h2 {
    font-family: 'Roboto Slab', serif;
    color: #2c3e50;
    margin-bottom: 20px;
  }
  p {
    font-size: 18px;
    color: #555;
    max-width: 800px;
  }
  .container {
    max-width: 800px;
    margin: auto;
    padding: 20px;
    background-color: #fff;
    box-shadow: 0 0 10px rgba(0, 0, 0, 0.05);
  }
  a {
    color: #2980b9;
    text-decoration: none;
  }
  a:hover {
    text-decoration: underline;
  }
  ul {
    padding-left: 20px;
  }
  .panelists {
    list-style-type: none;
    padding: 0;
  }
  .panelists li {
    margin-bottom: 10px;
  }
</style>
</head>
<body>

<div class="container">
  <h1>Panel on the Use of AI Tools for Mathematics Research</h1>

  <div class="response">
    <p>
      Our JMM 2025 panel, titled “The use of AI tools in Mathematics research”, brought together leading mathematicians and computer scientists working in the field of AI and mathematics. The motivation for the panel was two-fold: that these experts could accurately describe the current state of adoption of AI tools in mathematics research, and that the computer science community could get a better understanding of the kinds of tools that would be most useful for mathematicians.
    </p>
    <p>
      Given below is our recollection of the panelists' opinions and ideas at our 
      <a href="https://meetings.ams.org/math/jmm2025/meetingapp.cgi/Session/11074">JMM panel</a>.
      Any factual errors are the author's alone.
    </p>
  </div>
  
  <h2>Panelists</h2>
  <ul class="panelists">
    <li>Francois Charton (FAIR, Meta)</li>
    <li>Thomas Hubert (Google DeepMind)</li>
    <li>Alex Kontorovich (Rutgers University)</li>
    <li>Kaiyu Yang (FAIR, Meta)</li>
  </ul>
  
  <p>
    The discussion began with an exploration of the AI tools currently being utilized in mathematics research. Alex Kontorovich highlighted that foundational large language models (LLMs) like ChatGPT and Claude are widely used by mathematicians for their research. Additionally, tools such as Lean are gaining traction. Other notable tools mentioned include FunSearch, AlphaGeometry, and PatternBoost. He pointed out that while DeepMind is developing the Alpha family of technologies, access to these tools by mathematics professors could significantly aid in solving complex problems.
  </p>
  
  <p>
    Francois Charton shared his experience from a semester-long workshop at Harvard CMSA, where he assisted in solving complicated math problems using basic Transformers. He emphasized that Transformers have the capability to understand complex mathematical concepts and can provide solutions that might be challenging even for professional mathematicians.
  </p>
  
  <p>
    Moving on to the application of genetic evolution-based technologies like FunSearch and PatternBoost, the panel discussed their current use in constructing examples and counterexamples in combinatorics. Francois noted that combinatorics problems are more amenable to such methods due to their finite search spaces. However, extending these technologies to fields like differential geometry or analysis presents challenges. The moderator suggested that even in geometry, where there is often a finite list of manifolds to consider, automation through LLMs coupled with tools like FunSearch or PatternBoost could be feasible. Francois agreed, suggesting that geometry problems could be tackled by dividing manifolds into finite components, a potential area for future exploration.
  </p>
  
  <p>
    The conversation then shifted to AlphaProof, an AI tool nearing the proficiency of a gold medalist at the International Mathematical Olympiad (IMO). Thomas Hubert from Google DeepMind expressed that while they cannot comment on their current efforts, grounding LLMs with formal theorem provers like Lean is expected to yield significant results in proving research-level mathematical problems. Kaiyu Yang elaborated on AlphaProof's performance, noting that it successfully solved 18 out of 20 problems at the 2024 IMO. The two combinatorics problems that remained unsolved involved complex translations into Lean, highlighting the challenges in bridging natural language descriptions with formal proof systems. Kaiyu posited that the integration of LLMs with formal theorem provers holds promise for tackling some of the most challenging problems in mathematics.
  </p>
  
  <p>
    Addressing the skepticism around LLMs' understanding of mathematical concepts, Francois Charton argued that mathematical formulas can be encoded as sentences. In his research at Harvard CMSA, he demonstrated that transformers could translate mathematical questions and formulas into answers similarly to how one might translate English sentences into French. Alex Kontorovich provided a counterpoint by comparing ChatGPT's ability to play chess based solely on reading books about the game, suggesting that without a deeper understanding, LLMs might not reliably solve math problems merely by predicting the next token. Francois, however, maintained that transformer architectures are capable of reliably solving most mathematical problems and logical puzzles they are trained or fine-tuned on.
  </p>
  
</div>

</body>
</html>
