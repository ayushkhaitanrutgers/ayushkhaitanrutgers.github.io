<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Panel on the Use of AI Tools for Mathematics Research</title>
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&family=Roboto+Slab:wght@700&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Open Sans', sans-serif;
      line-height: 1.8; /* Increased for better readability */
      color: #333;
      background-color: #f8f8f8;
      padding: 20px;
    }
    h1, h2, h3 {
      font-family: 'Roboto Slab', serif;
      color: #1a73e8; /* Refined shade of blue */
      margin-bottom: 20px;
      font-weight: 700; /* Ensures headings are bold */
      letter-spacing: 0.5px; /* Subtle letter spacing */
    }
    h3 {
      font-size: 1.1em;
      margin-top: 30px;
    }
    p {
      font-size: 18px;
      color: #555;
      max-width: 800px;
      margin-bottom: 20px;
      line-height: 1.8; /* Consistent with body */
    }
    .container {
      max-width: 800px;
      margin: auto;
      padding: 20px;
      background-color: #fff;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05); /* Enhanced shadow for depth */
      border-radius: 8px; /* Rounded corners for a modern look */
    }
    a {
      color: #1a73e8; /* Match heading color for consistency */
      text-decoration: none;
      font-weight: 600; /* Semi-bold for better visibility */
      transition: color 0.3s ease;
    }
    a:hover {
      color: #0c47b7; /* Darker shade on hover */
      text-decoration: underline;
    }
    ul {
      padding-left: 20px;
    }
    .panelists {
      list-style-type: none;
      padding: 0;
    }
    .panelists li {
      margin-bottom: 10px;
      font-size: 18px; /* Same as paragraphs */
      line-height: 1.6;
    }
    .response {
      margin-left: 0;
    }
    /* Responsive Typography */
    @media (max-width: 768px) {
      body {
        padding: 15px;
      }
      .container {
        padding: 15px;
      }
      p, .panelists li {
        font-size: 16px; /* Slightly smaller on smaller screens */
      }
      h1 {
        font-size: 2em;
      }
      h2 {
        font-size: 1.75em;
      }
      h3 {
        font-size: 1em;
      }
    }
  </style>
</head>
<body>

<div class="container">
  <h1>Panel on the Use of AI Tools for Mathematics Research</h1>

  <div class="response">
    <p>
      The <a href="https://meetings.ams.org/math/jmm2025/meetingapp.cgi/Session/11074">JMM panel</a>, titled “The use of AI tools in Mathematics research” was organized by <a href="https://www.cs.utexas.edu/~swarat/">Swarat Chaudhuri</a>, <a href="https://ayushkhaitanrutgers.github.io">Ayush Khaitan</a> and <a href="https://amit9oct.github.io/aboutme/">Amitayush Thakur</a>. It brought together leading mathematicians and computer scientists working in the field of AI and mathematics. The motivation for the panel was two-fold: that these experts could accurately describe the current state of adoption of AI tools in mathematics research, and that the computer science community could get a better understanding of the kinds of tools that would be most useful for mathematicians.
    </p>
    <p>
      Given below are some highlights from our panel discussion.
      Any factual errors are the author's alone.
    </p>
  </div>
  
  <h2>Panelists</h2>
  <ul class="panelists">
    <li><a href="https://scholar.google.com/citations?user=1tMnd-4AAAAJ&hl=en">Francois Charton</a> (FAIR, Meta)</li>
    <li><a href="https://scholar.google.co.uk/citations?user=WXG0QfMAAAAJ&hl=en">Thomas Hubert</a> (Google DeepMind)</li>
    <li><a href="https://sites.math.rutgers.edu/~alexk/">Alex Kontorovich</a> (Rutgers University)</li>
    <li><a href="https://yangky11.github.io">Kaiyu Yang</a> (FAIR, Meta)</li>
  </ul>

  <p>
    Before the discussion began, the moderator welcomed the panelists and explained the structure of the panel. The moderator would ask questions either to a particular panelist or to all panelists collectively. The panelists were free to answer both types of questions. Moreover, the panelists were encouraged to get technical and also talk about their own research to better inform their answers.
  </p> 
  
  <h3>On the current use of AI tools in Mathematics Research</h3>
  <p>
    The discussion began by asking all the panelists about the kinds of AI tools currently being utilized in mathematics research. Alex highlighted that foundational large language models (LLMs) like ChatGPT and Claude are widely used by mathematicians for their research. He stated that discussing research ideas with a powerful LLM is akin to talking to an expert during tea time in his department. He also added that tools such as Lean are slowly gaining traction. Other notable tools mentioned include FunSearch, AlphaGeometry, and PatternBoost. He pointed out that while DeepMind is developing the Alpha family of technologies, access to these tools by mathematics professors could significantly help their research programs. Thomas agreed that open access to similar technologies would be helpful to mathematicians at universities. 
  </p>
  <p>
    Francois Charton also shared his experience from a semester-long workshop at Harvard CMSA, where he assisted in solving complicated math problems using basic Transformers. He emphasized that Transformers have the capability to understand complex mathematical concepts and can provide solutions that might be challenging even for professional mathematicians. 
  </p>
  
  <h3>On Funsearch and PatternBoost</h3>
  <p>
    Moving on to the application of technologies like FunSearch and PatternBoost, the panel discussed their current use in constructing examples and counterexamples in combinatorics. Francois noted that combinatorics problems are more amenable to such methods due to their finite search spaces. However, extending these technologies to fields like differential geometry or analysis presents challenges. The moderator suggested that even in geometry, where there is often a finite list of manifolds to consider, automation through LLMs coupled with tools like FunSearch or PatternBoost could be feasible. Francois agreed, suggesting that geometry problems could be tackled by dividing manifolds into finite components, a potential area for future exploration.
  </p>
  
  <h3>On AlphaProof and the IMO</h3>
  <p>
    The conversation then shifted to AlphaProof, an AI tool that is "almost" at the proficiency of a gold medalist at the International Mathematical Olympiad (IMO). Thomas expressed that while they cannot comment on their current efforts, grounding LLMs with formal theorem provers like Lean is expected to yield significant results in proving research-level mathematical problems. He further clarified that while AlphaProof had been trained on IMO problems, it had been trained in a way akin to how a human would train for it, as opposed to just memorizing large datasets of solutions. Hence, this approach held promise for solving research-level math problems. Kaiyu Yang elaborated on AlphaProof's performance, noting that it successfully solved 4 out of 6 problems at the 2024 IMO. The two combinatorics problems that remained unsolved involved the translation of non-standard words like "monsters" into Lean, which suggests that a more standard phrasing of the questions could have led AlphaProof to perform even better. Kaiyu posited that the integration of LLMs with formal theorem provers holds promise for tackling the most challenging problems in mathematics.
  </p>
  
  <h3>Do LLMs actually understand mathematics?</h3>
  <p>
    Addressing the skepticism around LLMs' understanding of mathematical concepts, Francois Charton argued that mathematical formulas can be encoded as sentences. In his research at Harvard CMSA, he demonstrated that transformers could translate mathematical questions and formulas into answers similarly to how one might translate English sentences into French. Alex Kontorovich provided a counterpoint by comparing ChatGPT's ability to play chess based solely on reading books about the game, suggesting that without a deeper understanding, LLMs might not reliably solve math problems merely by predicting the next token. Francois, however, maintained that transformer architectures are capable of reliably solving most mathematical problems and logical puzzles they are trained or fine-tuned on.
  </p>
  
  <h3>Conclusion</h3>
  <p>
    All in all, the discussion was electric, and the experts skillfully weaved together intuitive explanations as well as technical details into helpful and complete answers for the 100-odd mathematicians and computer scientists in the audience. At the end of the panel, there was a palpable feeling in the audience that something quite fundamental had changed about the nature of mathematics research, and that this wouldn't be the last panel on AI tools and math.   
  </p>
  
</div>

</body>
</html>
